# Steven Harrison's Data Science Portfolio

I am a Data Science with experience in the compliance, security and data governance domain expertise. I have thus far built my career at the intersection of data and IT security and compliance at Deloitte. While at Deloitte I worked as a consultant within the internal audit market offering. In this role I worked with clients in the high technology and internet industries to improve their IT security, data reliability and organizational management of data. It was there that developed a passion for working with data and identifying trends which were useful to my clients or issues in data pipelines causing erroneous data to appear in downstream repositories. It was after enjoying these projects at Deloitte that I decided that I would begin the transition to a full time data science role. 

To build more advanced skills in the data science area I have recently completed Brainstation’s Full Time Diploma program, a 12 week intensive bootcamp designed to provide all of the fundamental skills needed in the data science realm. Within this bootcamp I developed skills in data cleaning, data analysis, A/B testing and machine learning. I worked on projects with data cleaning, big data, machine learning and neural networks to develop a well rounded understanding of various different specializations within data science. 

#### Machine Learning

In this project I applied various different machine learning models from SciKit Learn’s libraries to identify fraudulent credit card transitions within a large dataset of transactions. I made use of features that were already reduced using principal component analysis to identify fraudulent transitions. The best models used were able to classify transitions with a 99.94 accuracy and an F1 score of 87 percent. In performing this analysis I tuned hyperparameters and applied grid searching to find the best possible hyperparameter combinations. 


#### Neural Networks


This project uses a neural network to classify political bias in news articles. The source of the data being used comes from the kaggle https://www.kaggle.com/snapcrack/all-the-news dataset. This project makes use of Google’s Universal Sentence encoder for text to numeric encoding and required data cleaning and feature engineering. 


#### Data visualizations

I have created visualizations to accompany a business analysis problem focused on the bixi bicycles space. This project showcases data visualizations in tableau.
